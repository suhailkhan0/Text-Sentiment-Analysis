{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/anonymous/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('punkt')  #Run this only one time to download model in system\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading  input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...\n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3      40  https://insights.blackcoffer.com/will-machine-...\n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = str(os.getcwd())\n",
    "input_data = pd.read_excel(str(path)+'/Input.xlsx')\n",
    "med_data = pd.read_excel(str(path)+'/Input.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the title and text of the articles from url and saving in a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(input_data)):\n",
    "    url = dict(input_data['URL'][i:i+1])\n",
    "    page = requests.get(url[i], headers = {'User-Agent': 'Chrome'}) # Here we get the html contents of web page\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    title = soup.find('title')  # This will get the title of the article\n",
    "    title = title.text\n",
    "    file_name = list(input_data['URL_ID'][i:i+1])\n",
    "    f = open('files/'+str(file_name[0]) + '.txt', 'w+', encoding = 'utf-8') # here we are creating text file wit url_id as its name and writing title and paragragh in the file\n",
    "    f.write(title +'\\n')\n",
    "    for para in soup.find_all('p'):   # This will get all the paragraphs in the article\n",
    "        f.write(para.text)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a list of all the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stopwords = []\n",
    "# Here we crete lists of all the stop words from differnt files and then creating a final list containing all the stopword lists.\n",
    "stopwords_files = ['Auditor','Currencies','DatesandNumbers','Generic','GenericLong','Geographic','Names']\n",
    "for i in range(0,len(stopwords_files)):\n",
    "    f = open(str(path)+'/StopWords/StopWords_'+stopwords_files[i]+'.txt','r',encoding='latin-1')\n",
    "    stopwords_files[i] = str(f.read())\n",
    "    stopwords_files[i] = stopwords_files[i].replace('\\n',',')\n",
    "    str_found = re.findall(r'\\|(.*?)[\\n|,]', stopwords_files[i])  # filtering the text file\n",
    "    stopwords_files[i] = stopwords_files[i].replace('|','')\n",
    "    stopwords_files[i] = stopwords_files[i].lower()\n",
    "    for j in str_found:                                             # Removing unnecessary items.\n",
    "        if j in stopwords_files[i]:\n",
    "            stopwords_files[i] = stopwords_files[i].replace(j,'')\n",
    "        else:\n",
    "            continue\n",
    "    stopwords_files[i] = list(stopwords_files[i].split(','))   \n",
    "    final_stopwords+=(stopwords_files[i])    # Final stopwords list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a list of positive and negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterwords_files = ['negative','positive']\n",
    "positive = ''\n",
    "negative = ''\n",
    "for i in range(0, len(masterwords_files)):\n",
    "    f = open(str(path)+'/MasterDictionary/'+masterwords_files[i]+'-words.txt','r',encoding='latin-1')\n",
    "    if i == 0:\n",
    "        negative = str(f.read())\n",
    "        negative = negative.lower()\n",
    "        negative = list(negative.split())   # Negative words list\n",
    "    else:\n",
    "        positive = str(f.read())\n",
    "        positive = positive.lower()\n",
    "        positive = list(positive.split())   # Positive words lists\n",
    "    f.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing article text in med df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>ai in healthcare to improve patient outcomes -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>what if the creation is taking over the creato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>what jobs will robots take from humans in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>will machine replace the human in the future o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>will ai replace us or work with us? - blackcof...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "\n",
       "                                            articles  \n",
       "0  ai in healthcare to improve patient outcomes -...  \n",
       "1  what if the creation is taking over the creato...  \n",
       "2  what jobs will robots take from humans in the ...  \n",
       "3  will machine replace the human in the future o...  \n",
       "4  will ai replace us or work with us? - blackcof...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.Series(dtype = 'str')\n",
    "for i in range(0,len(input_data)):\n",
    "    file_name = list(input_data['URL_ID'][i:i+1])\n",
    "    f = open('files/'+str(file_name[0]) + '.txt', 'r+', encoding = 'utf-8')\n",
    "    article = str(f.read())\n",
    "    article = article.lower()\n",
    "    m = pd.Series(article)\n",
    "    data = pd.concat([data, m])\n",
    "    f.close()\n",
    "data.index = [i for i in range(0,len(input_data))]\n",
    "med_data['articles'] = data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating all the necessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(med_data)):\n",
    "    filtered_words = []\n",
    "    pos_words = {positive[i]: 0 for i in range(0, len(positive))}   # dictionary of positve words \n",
    "    neg_words = {negative[i]: 0 for i in range(0, len(negative))}   # dictionary of  negative words\n",
    "    tokenized_sentences = sent_tokenize(med_data['articles'][i])    # creating list of sentences\n",
    "    tokenized_words = word_tokenize(med_data['articles'][i])        # creating list of words\n",
    "    for w in tokenized_words:           # Removing all the stopwords from the tokenized words.\n",
    "        if w not in final_stopwords:\n",
    "            filtered_words.append(w) \n",
    "    for pos in positive:                  # Calcutaing how many times a positive word occur in the filtered words\n",
    "        for fil1 in filtered_words:\n",
    "            if pos == fil1:\n",
    "                pos_words[pos] += 1\n",
    "            continue\n",
    "    pos_score = sum(pos_words.values())    # Total number of positive words in then article\n",
    "    med_data.loc[i:, 'Positive Score'] = pos_score\n",
    "   \n",
    "    for neg in negative:                  # Calcutaing how many times a negative word occur in the filtered words\n",
    "        for fil2 in filtered_words:\n",
    "            if neg == fil2:\n",
    "                neg_words[neg] += 1\n",
    "                continue\n",
    "    neg_score = sum(neg_words.values())    # Total number of negative words in then article\n",
    "    med_data.loc[i:, 'Negative Score'] = neg_score\n",
    "    med_data.loc[i:, 'Polarity'] =  (pos_score - neg_score)/((pos_score + neg_score) + 0.000001)    # Polarity of the article\n",
    "    med_data.loc[i:, 'Subjectivity Score'] = (pos_score + neg_score)/(len(filtered_words) + 0.000001)\n",
    "    average_sentence_length = int(len(filtered_words)/len(tokenized_sentences))\n",
    "    med_data.loc[i:, 'Average Sentence Length'] = average_sentence_length\n",
    "    complex_count = 0            # Calculating the number of complex words\n",
    "    total_syl = 0\n",
    "    vowels = ['a','e','i','o','u']\n",
    "    for t in filtered_words:\n",
    "        syl = 0\n",
    "        for u in t:\n",
    "            for v in vowels:\n",
    "                if u == v:\n",
    "                    syl +=1\n",
    "                else:\n",
    "                    continue\n",
    "        total_syl += syl\n",
    "        if syl > 2:\n",
    "            complex_count += 1\n",
    "        else:\n",
    "            continue\n",
    "    percent = (complex_count/len(filtered_words))*100   # %age of complex words in the article\n",
    "    med_data.loc[i:, 'Percentage Of Complex Words'] = percent\n",
    "    fog = 0.4 * (average_sentence_length + percent)   # Fogging index value for each article\n",
    "    med_data.loc[i:, 'Fog Index'] = fog\n",
    "    med_data.loc[i:, 'Average Number of Words Per Sentence'] = int(len(filtered_words)/len(tokenized_sentences))\n",
    "    med_data.loc[i:, 'Complex Word Count'] = complex_count  # total complex words in the article\n",
    "    filtered_string = ' '.join([str(item) for item in filtered_words])    # Removing the punctuation from the article to calculate the word count\"\"\"\n",
    "    exclude = set(string.punctuation)\n",
    "    filtered_article = ''.join(ch for ch in filtered_string if ch not in exclude)\n",
    "    filtered_article = list(filtered_article.split(' '))\n",
    "    med_data.loc[i:, 'Word Count'] = len(filtered_article)      # total words in the article without the punctuation\n",
    "    med_data.loc[i:, 'Syllable Count Per Word'] = int(total_syl/ len(filtered_words))\n",
    "    pronounRegex = re.compile(r'\\b(I|we|my|ours|(?-i:us))\\b',re.I)  # Calculating the number of times personal pronouns are used in the article\"\"\"\n",
    "    pronouns = pronounRegex.findall(med_data['articles'][i])\n",
    "    med_data.loc[i:, 'Personal Pronouns'] = len(pronouns)\n",
    "    characters = 0\n",
    "    for i in filtered_words:\n",
    "        characters += len(i)\n",
    "    med_data.loc[i:, 'Average Word Length'] = characters/len(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Positive Score</th>\n",
       "      <th>Negative Score</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity Score</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Percentage Of Complex Words</th>\n",
       "      <th>Fog Index</th>\n",
       "      <th>Average Number of Words Per Sentence</th>\n",
       "      <th>Complex Word Count</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Syllable Count Per Word</th>\n",
       "      <th>Personal Pronouns</th>\n",
       "      <th>Average Word Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.074419</td>\n",
       "      <td>23.0</td>\n",
       "      <td>51.472868</td>\n",
       "      <td>29.789147</td>\n",
       "      <td>23.0</td>\n",
       "      <td>664.0</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.129206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.242105</td>\n",
       "      <td>0.103373</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.043526</td>\n",
       "      <td>21.217410</td>\n",
       "      <td>13.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.129206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.090043</td>\n",
       "      <td>16.0</td>\n",
       "      <td>51.082251</td>\n",
       "      <td>26.832900</td>\n",
       "      <td>16.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.129206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.091205</td>\n",
       "      <td>11.0</td>\n",
       "      <td>43.105320</td>\n",
       "      <td>21.642128</td>\n",
       "      <td>11.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>921.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.129206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.071749</td>\n",
       "      <td>16.0</td>\n",
       "      <td>41.345291</td>\n",
       "      <td>22.938117</td>\n",
       "      <td>16.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.129206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  Positive Score  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...            66.0   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...            59.0   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...            68.0   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...            62.0   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...            57.0   \n",
       "\n",
       "   Negative Score  Polarity  Subjectivity Score  Average Sentence Length  \\\n",
       "0            30.0  0.375000            0.074419                     23.0   \n",
       "1            36.0  0.242105            0.103373                     13.0   \n",
       "2            36.0  0.307692            0.090043                     16.0   \n",
       "3            22.0  0.476190            0.091205                     11.0   \n",
       "4            23.0  0.425000            0.071749                     16.0   \n",
       "\n",
       "   Percentage Of Complex Words  Fog Index  \\\n",
       "0                    51.472868  29.789147   \n",
       "1                    40.043526  21.217410   \n",
       "2                    51.082251  26.832900   \n",
       "3                    43.105320  21.642128   \n",
       "4                    41.345291  22.938117   \n",
       "\n",
       "   Average Number of Words Per Sentence  Complex Word Count  Word Count  \\\n",
       "0                                  23.0               664.0      1290.0   \n",
       "1                                  13.0               368.0       919.0   \n",
       "2                                  16.0               590.0      1155.0   \n",
       "3                                  11.0               397.0       921.0   \n",
       "4                                  16.0               461.0      1115.0   \n",
       "\n",
       "   Syllable Count Per Word  Personal Pronouns  Average Word Length  \n",
       "0                      2.0                3.0             6.129206  \n",
       "1                      2.0                9.0             6.129206  \n",
       "2                      2.0                5.0             6.129206  \n",
       "3                      2.0               20.0             6.129206  \n",
       "4                      2.0               20.0             6.129206  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data = pd.DataFrame(med_data)\n",
    "output_data.drop('articles',axis= 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is written to Excel File successfully.\n"
     ]
    }
   ],
   "source": [
    "file_name = 'Output Data Structure.xlsx'  \n",
    "#saving in the excel format\n",
    "output_data.to_excel(file_name)\n",
    "print('DataFrame is written to Excel File successfully.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
